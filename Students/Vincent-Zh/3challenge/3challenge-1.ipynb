{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3: Parameter Estimation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to import data from the given file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 9)\n",
      "(5000, 9)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_csv(\"3challenge-1.csv\")\n",
    "dftraining = df.loc[~np.isnan(df['label'])]\n",
    "dftesting = df.loc[np.isnan(df['label'])]\n",
    "print(dftraining.shape)\n",
    "print(dftesting.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can use the data in their original Pandas DataFrame format, or one can transform these objects into Numpy-arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrainingData = dftraining.as_matrix(columns=None)\n",
    "TestData = dftesting.as_matrix(columns=['Y0', 'Y1', 'Y2', 'Y3', 'Y4', 'Y5', 'Y6', 'Y7'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating an algorithm and generating labels, one should update the original CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know Y0,Y1,...,Y7 are iid $B(40,\\theta)$,\n",
    "\n",
    "we set $\\hat{\\theta} = \\frac{\\bar{X}}{40}$, then $E(\\hat{\\theta}) = \\theta$, $Var(\\hat{\\theta}) = \\frac{\\theta(1-\\theta)}{320}$.\n",
    "\n",
    "If $Var(\\hat{\\theta})$ = CRLB, then $\\hat{\\theta}$ should be minimal variance unbiased estimator.\n",
    "\n",
    "Log-likelihood function is :\n",
    "\n",
    "$log\\,f_{X}(x;\\theta)=log\\prod_{i=1}^{8}{C_{x_{i}}^{40}\\theta^{x_{i}}(1-\\theta)^{40-x_{i}}}=\\sum_{i=1}^{8}{logC_{x_{i}}^{40}} + \\sum_{i=1}^{8}{x_{i}log\\theta} + \\sum_{i=1}^{8}(40-x_{i})log(1-\\theta)$\n",
    "\n",
    "$I_{X}(\\theta) = -E(\\frac{\\partial^{2}log\\,f_{X}(x;\\theta)}{\\partial \\theta^{2}}) = E(\\sum_{i=1}^{8}{\\frac{x_{i}}{\\theta^{2}}}+\\sum_{i=1}^{8}{\\frac{40-x_{i}}{(\\theta-1)^{2}}}) = \\frac{320}{\\theta(1-\\theta)}$\n",
    "\n",
    "$LB_{Cramer-Rao}\\geq I_{X}^{-1}(\\theta) = \\frac{\\theta(1-\\theta)}{320} = Var(\\hat{\\theta})$\n",
    "\n",
    "Therefore, $\\hat{\\theta}$ is the minimal variance unbiased estimator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.80450764543\n"
     ]
    }
   ],
   "source": [
    "A=np.mat([1/320,1/320,1/320,1/320,1/320,1/320,1/320,1/320])\n",
    "A=A.T\n",
    "y_est=np.mat(TrainingData[:,0:8])*A\n",
    "y=np.reshape(TrainingData[:,8],(5000,1))\n",
    "var=(y-y_est).T*(y-y_est)\n",
    "print(var[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value above is the MSE of MVU estimator in theory. We even don't need training data for this estimator.\n",
    "\n",
    "I'll try to make a linear regression for training data and design another estimator in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7456056673\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(TrainingData[:,0:8], TrainingData[:,8])\n",
    "y_lr=regr.predict(TrainingData[:,0:8])\n",
    "y_lr=np.mat(y_lr).T\n",
    "var_lr=(y-y_lr).T*(y-y_lr)\n",
    "print(var_lr[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems contradictive that MSE of linear regression estimator is less than the CRLB. \n",
    "\n",
    "But this could be reasonable. The theoretical MMSE(CRLB) is the expectation of MSE, i.e. when the number of observation approaches to infinity, the MSE of any estimator should no less than CRLB. While, there are only 5000 observations in this training set. \n",
    "\n",
    "For training set, this linear regression estimator has smaller MSE but it's not unbiased.\n",
    "\n",
    "In conclusion, $\\hat{\\theta}$ should be the best estimator for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pre=np.mat(TestData)*A\n",
    "Array=np.append(TestData,y_pre,axis=1)\n",
    "dftesting=pd.DataFrame(Array,columns=['Y0', 'Y1', 'Y2', 'Y3', 'Y4', 'Y5', 'Y6', 'Y7','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([dftraining, dftesting], join='outer', ignore_index=True)\n",
    "df.to_csv(\"3challenge-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
