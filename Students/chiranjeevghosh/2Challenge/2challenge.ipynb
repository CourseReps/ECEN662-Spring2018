{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1: Binary Detection 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to import data from the given file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 9)\n",
      "(5000, 9)\n",
      "(5000, 9)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_csv(\"2challenge.csv\")\n",
    "df0 = df.loc[df['label'] == 0.0]\n",
    "df1 = df.loc[df['label'] == 1.0]\n",
    "dftest = df.loc[~((df['label'] == 0.0) | (df['label'] == 1.0))]\n",
    "print(df0.shape)\n",
    "print(df1.shape)\n",
    "print(dftest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can use the data in their original Pandas DataFrame format, or one can transform these objects into Numpy-arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData0 = df0.as_matrix(columns=None)\n",
    "TrainingData1 = df1.as_matrix(columns=None)\n",
    "TestData = dftest.as_matrix(columns=['Y0', 'Y1','Y2','Y3','Y4','Y5','Y6','Y7'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be helpful to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate missing data using normal distribution with mean and variance of given data in corresponding column\n",
    "def Data_Estimator(nparray):\n",
    "    blank = np.argwhere(np.isnan(nparray))\n",
    "    lt_dim = len(nparray) - len(blank)\n",
    "    local_temp = np.zeros(lt_dim)\n",
    "    for i in range(len(blank)):\n",
    "        nparray[blank[i]] = -1      # Marking blank space distinctly\n",
    "    cnt = 0;\n",
    "    for j in range(len(nparray)):\n",
    "        if nparray[j] != -1:\n",
    "            local_temp[cnt] = nparray[j]\n",
    "            cnt = cnt + 1\n",
    "    sigma = math.sqrt(np.var(local_temp))\n",
    "    mu = np.mean(local_temp)\n",
    "    for k in range(len(nparray)):\n",
    "        if nparray[k] == -1:\n",
    "            nparray[k] = np.random.normal(mu,sigma,1)\n",
    "    return nparray;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating an algorithm and generating labels, one should update the original CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Label0: , Label1: ', 239, 4761)\n"
     ]
    }
   ],
   "source": [
    "# Idea behind the algorithm is to select the test point and take the closest 25 training points to that point.\n",
    "# The label of the most closest number of points decides the label for the test data point in question. I choose\n",
    "# 25 points for the proximity test because the borderline estimation criteria is 13 closest points of a particular label, \n",
    "# which is ~52% of the total sample points, which is closer to the prioris given(50% each). I choose not to increase \n",
    "# the proximity points in order to sustain computation time. \n",
    "\n",
    "T_Array = np.append(TrainingData0, TrainingData1, axis=0)\n",
    "T_Data = np.array(TestData)\n",
    "\n",
    "TrainingData0[:,6] = Data_Estimator(TrainingData0[:,6])\n",
    "TrainingData0[:,7] = Data_Estimator(TrainingData0[:,7])\n",
    "TrainingData1[:,6] = Data_Estimator(TrainingData1[:,6])\n",
    "TrainingData1[:,7] = Data_Estimator(TrainingData1[:,7])\n",
    "TestData[:,6] = Data_Estimator(TestData[:,6])\n",
    "TestData[:,7] = Data_Estimator(TestData[:,7])\n",
    "\n",
    "Training_Array = np.append(TrainingData0, TrainingData1, axis=0);\n",
    "new_c0 = 0;\n",
    "new_c1 = 0;\n",
    "\n",
    "\n",
    "num_data_points = TestData.shape[0];\n",
    "num_training_points = Training_Array.shape[0];\n",
    "estimation = np.zeros((num_data_points,1));\n",
    "\n",
    "for i in range(num_data_points):\n",
    "    y0 = TestData[i,0];\n",
    "    y1 = TestData[i,1];\n",
    "    y2 = TestData[i,2];\n",
    "    y3 = TestData[i,3];\n",
    "    y4 = TestData[i,4];\n",
    "    y5 = TestData[i,5];\n",
    "    y6 = TestData[i,6];\n",
    "    y7 = TestData[i,7];\n",
    "    Distance_Vector = np.zeros((num_training_points,2));\n",
    "    count_0 = 0;\n",
    "    count_1 = 0;\n",
    "    for j in range(num_training_points):\n",
    "        x0 = Training_Array[j,0];\n",
    "        x1 = Training_Array[j,1];\n",
    "        x2 = Training_Array[j,2];\n",
    "        x3 = Training_Array[j,3];\n",
    "        x4 = Training_Array[j,4];\n",
    "        x5 = Training_Array[j,5];\n",
    "        x6 = Training_Array[j,6];\n",
    "        x7 = Training_Array[j,7];\n",
    "        dist = math.sqrt((x0 - y0)**2 + (x1 - y1)**2 + + (x2 - y2)**2 + (x3 - y3)**2 + (x4 - y4)**2 + (x5 - y5)**2 + + (x6 - y6)**2 + (x7 - y7)**2);\n",
    "        Distance_Vector[j,0] = dist;\n",
    "        Distance_Vector[j,1] = Training_Array[j,8];\n",
    "    A = Distance_Vector[:,0];\n",
    "    min_idx = np.argpartition(A,25);\n",
    "    for p in range(25):\n",
    "        if Distance_Vector[min_idx[p],1] == 0:\n",
    "            count_0 = count_0 + 1;\n",
    "        else:\n",
    "            count_1 = count_1 + 1;\n",
    "    \n",
    "       \n",
    "    if count_1 > count_0:\n",
    "        new_c1 = new_c1 + 1;\n",
    "        estimation[i] = 1;\n",
    "    else:\n",
    "        new_c0 = new_c0 + 1;\n",
    "        estimation[i] = 0;\n",
    "        \n",
    "Temp_Data_Array = np.append(T_Data,estimation,axis=1);\n",
    "Array = np.append(T_Array,Temp_Data_Array,axis=0);\n",
    "print (\"Label0: , Label1: \", new_c0, new_c1);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfupdate = pd.DataFrame({'Y0':Array[:,0],'Y1':Array[:,1],'Y2':Array[:,2],'Y3':Array[:,3],'Y4':Array[:,4],'Y5':Array[:,5],'Y6':Array[:,6],'Y7':Array[:,7],'label':Array[:,8]});\n",
    "dfupdate.to_csv(\"2challenge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
